---
title: "Reproducible_Research_Course_Project_2"
author: "J Go"
date: "June 14, 2016"
output: html_document
---

### Title: An Exploration of the NOAA Storm Database to Determine Health and 
###        Economic Effects of Severe Weather Events in the United States

### Synopsis

```
# Synopsis: Immediately after the title, there should be a synopsis which 
# describes and summarizes your analysis in at most 10 complete sentences.

The goal of this document is to explore the NOAA Storm Database and answer the 
following two basic questions about severe weather events. 

1. Across the United States, which types of events (as indicated in the 
ğ™´ğš…ğšƒğšˆğ™¿ğ™´ variable) are most harmful with respect to population health?

2.  Across the United States, which types of events have the greatest economic 
consequences?

The code for the entire analysis, and key results, are included with the 
intention of making the entire analysis readily reproducible. 

Possible audiences may include: government or municipal managers responsible for 
preparing for severe weather events who need to prioritize resources for 
different types of events, and fellow students and practitioners of data science 
who may find the methods of analysis and documentation of interest. 

Disclaimer: Please note that the analysis does not make any determination or
recommendation for any specific course of action or measure to be taken.  
Further the analysis does not constitute an endorsement or validation of any of
the methods, software, hardware, or results used or obtained herein.
```

### Data Processing

There should be a section titled Data Processing which describes (in words and code) how the data were loaded into R and processed for analysis. In particular, your analysis must start from the raw CSV file containing the data. You cannot do any preprocessing outside the document. If preprocessing is time-consuming you may consider using the ğšŒğšŠğšŒğš‘ğš = ğšƒğšğš„ğ™´ option for certain code chunks.
There should be a section titled Results in which your results are presented.
You may have other sections in your analysis, but Data Processing and Results are required.
The analysis document must have at least one figure containing a plot.
Your analysis must have no more than three figures. Figures may have multiple plots in them (i.e. panel plots), but there cannot be more than three figures total.
You must show all your code for the work in your analysis document. This may make the document a bit verbose, but that is okay. In general, you should ensure that ğšğšŒğš‘ğš˜ = ğšƒğšğš„ğ™´ for every code chunk (this is the default setting in knitr).
```

```

### require needed packages
```{r load_packages}
library(dplyr)
library(lubridate)      # for date functions
library(ggplot2)
```
### examine session information
```{r examine session info}
sessionInfo()
```

### examine current directory and current files
```{r examine_current_dir_and_files}
getwd()
dir(full.names = TRUE, recursive = TRUE)
```

### check for "data" and "doc" directories, create if necessary
```{r check_existence_data_dir_doc_dir}
data_dir="./data"
if (!file.exists(data_dir)) {
    dir.create(data_dir)
} else {
    cat('data dir exists from previous run: [', data_dir, ']', '\n')
}
doc_dir="./doc"
if (!file.exists(doc_dir)) {
    dir.create(doc_dir)
} else {
    cat('doc dir exists from previous run: [', doc_dir, ']', '\n')
}
```

### check for repdata-data-StormData.csv.bz2 file, download into data dir if necessary
```{r check_existence_file_repdata-data-StormData.csv.bz2}
data_file <- paste0(file.path(".", "data", "repdata-data-StormData.csv.bz2"))
if(!file.exists(data_file)) {
    file1Url <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
    download.file(file1Url, destfile = "./data/repdata-data-StormData.csv.bz2", method = "curl")
    dateDownloaded <- date()
} else {
    cat('data file: [', data_file, '] was downloaded in a previous run \n')
    cat('on [', dateDownloaded, '] \n')
}
```
### check for doc file, download into doc dir if necessary ~ not working, debug later
```{r check_existence_doc_file}
# doc_file <- paste0(file.path(".", "doc", "repdata-peer2_doc-pd01016005curr.pdf"))
# if(!file.exists(doc_file)) {
# doc1URL <- "https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf";
# download.file(doc1Url, destfile = "./doc/repdata-peer2_doc-pd01016005curr.pdf", method = "curl");
# dateDocDownloaded <- date();
# cat('doc file: [', doc_file, '] was downloaded in current run on: \n');
# cat('[', dateDocDownloaded, '] \n');
# } else {
#    cat('doc file: [', doc_file, '] was downloaded in a previous run \n');
#    cat('on [', dateDocDownloaded, '] \n');
# }
```

```{r read storm data file}
# storm <- read.csv(bzfile("./data/repdata-data-StormData.csv.bz2")) 

# if (!exists("storm")) {  # this not working
# } else {
#   cat('storm data was read in during a previous run\n')
# }
str(storm)
summary(storm)
```
